---
title: "Gut feeling"
pubDate: "2025-12-14"
description: "Exploring the connection between neural networks and human intuition."
tags:
  - AI
  - Philosophy
---

Day one of learning about neural networks, so this could be misguided.

Earlier this month, I had to make a hard decision. I'm unsure to this day whether I did the right thing. The confusion lingered enough that I ended up reading about hard decisions, including Ruth Chang's work on the topic.

Chang argues that once the standard reasons (those dictated by society, morality, or third parties) run out, it's up to the rational agent to generate reasons. Those self-authored reasons are what make you who you are.

I agree with her claim that hard decisions are not about choosing between equivalent alternatives. If two options were truly equivalent, the decision would be trivial. Leaving a meaningful decision to chance would be absurd in almost any real-world scenario.

That said, my own decision-making process in this case looked different. I gravitated toward one alternative almost immediately and only afterward tried to rationalize it. There was never a genuine internal debate or a pros-and-cons list. It would have been useless. I was already biased and heavily leaning one way.

This pattern is well known in psychology and is often summarized by the claim:

> *Most intelligence happens below awareness.*

A classic example is chess. Strong players often feel that a tactic exists in a position before they can articulate it, and only then search for the concrete continuation.

So where does AI come in?

Hidden layers in neural networks are famously opaque. It's often unclear what level of abstraction they operate on. Even when a network produces the correct output, explaining how it arrived there may be difficult or impossible.

By the time a signal reaches the output layer, the original evidence has been abstracted, compressed, and transformed to the point of unintelligibility. What remains is something closer to a conclusion than an argument. It resembles a kind of artificial gut feeling.

In that sense, explicit reasoning isn't the source of many decisions. It's often a post-hoc narrative we tell ourselves once the decision has already been made.

Humans are obviously far more complex, but the comparison is still useful. There's nothing mystical about gut feelings: they're conclusions (potentially rational, based on pattern recognition, etc.) where the evidence is no longer available.
